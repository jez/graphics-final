---
layout: post
title: "Final Report"
date: "Thu Dec 16 15:14:35 EST 2015"
---

## Building and Running

The instructions to build and run are identical to those for Assignment 3.

## Results

My first goal was to implement the Approximate Agglomerate Clustering algorithm
for BVH build acceleration. This algorithm sacrifices potential build quality
for locally optimal decisions.

My second goal was to parallelize this algorithm. For this task, I chose OpenMP
because it makes fork-join parallelism easy, and I had experience using this
library in a prior class (15-418). This portion turned out to be easier than
anticipated, because I implemented the core subroutines of the algorithm using
`const` functions, so I knew that I had clear guarantees about memory accesses
across threads.

Here are some of the results I achieved:

`./pathtracer ../dae/sky/blob.dae`

| Algorithm (Max Leaf Size) | Build Time | Render Time |
| ------------------------- | ---------- | ----------- |
| Recursive SAH (4)         | 2.0232 sec | 28.9634 sec |
| AAC (4)                   | 0.8198 sec | 87.8281 sec |
| AAC (20)                  | 1.5859 sec | 34.9350 sec |

`./pathtracer ../dae/meshedit/beast.dae`

| Algorithm (Max Leaf Size) | Build Time | Render Time |
| ------------------------- | ---------- | ----------- |
| Recursive SAH (4)         | 0.5662 sec |  3.0803 sec |
| AAC (4)                   | 0.2887 sec |  7.1478 sec |
| AAC (30)                  | 0.6130 sec |  3.0214 sec |

`./pathtracer ../dae/meshedit/cow.dae`

| Algorithm (Max Leaf Size) | Build Time | Render Time |
| ------------------------- | ---------- | ----------- |
| Recursive SAH (4)         | 0.0372 sec |  2.3346 sec |
| AAC (4)                   | 0.0183 sec |  3.7988 sec |
| AAC (30)                  | 0.0472 sec |  2.6320 sec |



## Takeaway

The general trend seems to be that the build time is definitely faster, but at
the cost of render times, which is unfortunately not a winning tradeoff. The
good news is that we could potentially use this algorithm if what we really
needed was short build times.

This could potentially be the case where we're trying to render a really low
quality scene in a game. In these circumstances, we might care more about
_correctness_ ("is there an object in front of me or not?") versus _quality_
("is this scene beautifully detailed?").

## Future Work

The paper obviously reported more impressive results than those I've described
here. This could be due to a number of reasons.

First of all, test scenes might have been more primitive-dense, i.e., more
primitives concentrated in a given volume. These types of scenes would be more
amenable to this type of algorithm (parallelism).

The paper itself suggests a number of tweaks and optimizations that they
combined to eke out more performance. I just substituted the constants they
arrived at, but performance could likely be improved by tweaking these for my
particular setup (processor, cache size, etc.).

## Note to the Grader

In closing, I wanted to take the time to thank you (the course staff) for all
your hard work. From one TA to another, I have an idea of how much work is
involved in running a course, but I can only imagine how much more there is when
rearchitecting a course from scratch.

I can without a doubt say that I got everything out of this course that I wanted
to. I have so much more of an understanding of graphics programming, graphical
algorithms, differential calculus, linear algebra, and more just from taking
this course, and I can tell it's the kind of knowledge that I won't forget
easily. This simply wouldn't have been the case without such a great course
staff.

Thank you so much for all your work! I had tons of fun this semester.
